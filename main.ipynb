{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "transfer_learning(fyp).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbUeIyZHwdOI"
      },
      "source": [
        "# Connect with google drive \n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b70wesxY4r74"
      },
      "source": [
        "# Package included remove package that should not be include\n",
        "\n",
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Dense,GlobalAveragePooling2D, MaxPooling2D, Dropout\n",
        "from tensorflow.keras.applications import MobileNet,ResNet101,InceptionV3,VGG16,VGG19, DenseNet121\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BE0cqNUAnSYi"
      },
      "source": [
        "# Call dataset \n",
        "\n",
        "# ************************NEU dataset*************************\n",
        "DATADIR = \"/content/drive/MyDrive/Steel/defect_data/defect_dataset1\"\n",
        "CATEGORIES = [\"crazing\", \"rolled_in_scale\",\"pitted_surface\",\"patches\",\"inclusion\",\"scratches\",\"no_defect\"]\n",
        "# ************************SEVERSTAL dataset*************************\n",
        "#DATADIR = \"./lala\"\n",
        "#CATEGORIES = [\"defect\", \"no_defect\"]\n",
        "\n",
        "# Pre-processing\n",
        "\n",
        "for category in CATEGORIES:  # do dogs and cats\n",
        "    path = os.path.join(DATADIR,category)  # create path to dogs and cats\n",
        "    for img in os.listdir(path):  # iterate over each image per dogs and cats\n",
        "        img_array = cv2.imread(os.path.join(path,img) )  # convert to array ,cv2.IMREAD_GRAYSCALE\n",
        "        #plt.imshow(img_array, cmap='gray')  # graph it\n",
        "        #plt.show()  # display!\n",
        " \n",
        "        break  # we just want one for now so break\n",
        "    break \n",
        " \n",
        "training_data = []\n",
        " \n",
        "def create_training_data():\n",
        "    for category in CATEGORIES:  # do dogs and cats\n",
        " \n",
        "        path = os.path.join(DATADIR,category)  # create path to dogs and cats\n",
        "        class_num = CATEGORIES.index(category)  # get the classification  (0 or a 1). 0=dog 1=cat\n",
        " \n",
        "        for img in tqdm(os.listdir(path)):  # iterate over each image per dogs and cats\n",
        "          if img.endswith(\"jpg\"):\n",
        "            img_array = cv2.imread(os.path.join(path,img)) # ,cv2.IMREAD_GRAYSCALE# convert to array ,cv2.IMREAD_GRAYSCALE\n",
        "            new_array = cv2.resize(img_array, (32, 32))  # resize to normalize data size\n",
        "            training_data.append([new_array, class_num])  # add this to our training_data\n",
        " \n",
        "create_training_data()\n",
        " \n",
        "print(len(training_data))\n",
        "\n",
        "# Split dataset 80:20 ratio \n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "X = []\n",
        "y = []\n",
        " \n",
        "for features,label in training_data:\n",
        "    X.append(features)\n",
        "    y.append(label)\n",
        " \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20,stratify=y, random_state=42, shuffle=True)\n",
        " \n",
        "x_train = np.asarray(X_train,dtype=np.float32)/255.0\n",
        "print(\"image shape:\",x_train[0].shape)\n",
        "print(\"total image shape:\",x_train.shape)\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=7, dtype='float32')# change the number class\n",
        "x_test = np.asarray(X_test,dtype=np.float32)/255.0\n",
        "print(\"image shape:\",x_test[0].shape)\n",
        "print(\"total image shape:\",x_test.shape)\n",
        "y_test2 = tf.keras.utils.to_categorical(y_test, num_classes=7, dtype='float32')# change number class \n",
        "\n",
        "# Training using Transfer Learning\n",
        "#choose suitable transfer learning\n",
        "base_model=MobileNet(weights='imagenet',include_top=False) # input_shape=(None,None,3)imports the mobilenet model and discards the last 1000 neuron layer.\n",
        "start=time.time()\n",
        "\n",
        "# Classify the dataset\n",
        "x=base_model.output\n",
        "x=GlobalAveragePooling2D()(x)\n",
        "x=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
        "x=Dense(1024,activation='relu')(x) #dense layer 2\n",
        "x=Dense(512,activation='relu')(x) #dense layer 3\n",
        "x=Dropout(0.5)(x)\n",
        "preds=Dense(7,activation='softmax')(x) #final layer with softmax activation change based on class\n",
        " \n",
        "model=Model(inputs=base_model.input,outputs=preds)\n",
        " \n",
        "#to freeze and unfreeze the layer\n",
        "for layer in model.layers[:20]:\n",
        "    layer.trainable=True\n",
        " \n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        " \n",
        "history = model.fit(x_train,y_train,validation_data=(x_test,y_test2),batch_size=32,epochs=50)\n",
        "score=model.evaluate(x_test,y_test2,verbose=0)\n",
        "print(\"accuracy = \",score[1])\n",
        "end=time.time()\n",
        "print(f\"time taken = {end-start}\")\n",
        "#model.summary()\n",
        "\n",
        "#plot the performance of the project\n",
        "plt.plot(history.history['loss'], label = \"Train\") \n",
        "plt.plot(history.history['val_loss'], label = \"Validation\")\n",
        "plt.title(\"losses\")\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.plot(history.history['accuracy'], label = \"Train\")\n",
        "plt.plot(history.history['val_accuracy'], label = \"Validation\") \n",
        "plt.title(\"Model Accuracy\")\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"Accuracy[%]\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nhodNcZ6400"
      },
      "source": [
        "# Save the training model in H5 model for Develop GUI\n",
        "model.save(\"steel.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}